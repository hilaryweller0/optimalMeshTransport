Mike: c-convexity is defined in Definition 2.10 of Guillen and Kitagawa http://arxiv.org/pdf/1212.4865v2.pdf. This paper contains a lot more which would be good background to help your understanding, particularly sections 2.1 and 2.2. Probably Villani (2009) is the best reference.

HW: Phil has now defined c-convexity in section 3.2 and used this definition to prove the existence and uniqueness of solutions on the surface of the sphere

Mike: The issue with naive discretisations of Monge Ampere is described in sections 3.1 and 3.2 of Froese, Oberman and  Salvador http://arxiv.org/pdf/1502.04969v1.pdf. There may well be better references including earlier publications by those authors. Chris may well suggest one. The point is that a naive method does not work, so you have to use the sort of pragmatic methods you describe. (An interesting idea described in Banff was the use of adaptive stencils which can allow for strongly anisotropic solutions.)

HW: Thanks for pointing out this great arxiv paper. I now refer to it in sections 2 and 3.3.1. I already referred to one of their papers in section 2. I am now beginning to get a bit more of an understanding of what they are talking about and have related it to my work.

Mike: It is important to make the point that a solution of Monge Ampere only controls det Hess(I+\nabla\phi), not the individual eigenvalues of Hess(I+\nabla\phi). If one eigenvalue gets large and the other small the Laplacian preconditioning will fail (hence the need for under-relaxation), cells though convex will be very anisotropic and may well be larger in one direction than the cells of the uniform mesh. Second derivative control is better in periodic geometry and with a smooth monitor function. However, anisotropy of the mesh is highly advantageous in cases like the Budd and Walsh frontal simulations, and is potentially advantageous in the situations shown by Phil’s grids. Chris may want to quote his own work in this area if published, but you could also use Loeper’s paper.

Hilary: I have very briefly looked at "Delanoe and Loeper: Gradient estimates for potentials of invertible gradient-mappings on the sphere" and "Loeper and Villani, Regularity of optimal transport in curved geometry: the nonfocal case". I'm afraid that they are a bit beyond me and I cannot see how to cite them in a way that brings insight to my work.

I have put some of Mike's words at the end of section 3.3.1 (about under-relaxation).

Mike: U is BV if it is in L^1 and the inner product <Du,\phi>. Is bounded for all \phi which are continuous, compactly supported and bounded.

Mike: BV stands for 'bounded variation'. Though a function may have a small number of jumps, it cannot oscillate too fast. The gradient of a convex function is BV. I think the gradient of a c-convex function is also BV but don't know of a reference for this. In my definition \phi has the same number of components as U so you can calculate the inner product.

Hilary: It looks as if \phi needs the same number of components as Du, not as U.

I have put something on bounded variation in 3.4.3. However I have not used the definition in the derivation of a gradient. Future work?

Mike: If you solve det D^2\phi=\nu, you would like to estimate the magnitude of the individual second derivatives of \phi. This will then allow you to estimate the eigenvalues of the Hessian. If these are bounded away from zero and infinity you can control the aspect ratio of each cell on the grid.

Hilary: I have discussed this comment with Phil and looked at Chris's work on (his definition of) skewness. Based on these, I haven't made any changes to the manuscript based on Mike's comment. It would appear that no change is needed. 

Mike: In section 3.2 you could rewrite the first unnumbered equation as T\xi=x as in Phil's note, and then write (5) as T_\# (r\cal L)^{-1}=\cal L  (*), where r is the function r(\phi) as you have defined it and \cal L is Lebesgue measure. This is written into Phil's note. Once you have said this section 3.4.2.2 can be stated to be a discretisation of (*). 

Hilary: I have re-organised so that Phil's material about optimal transport on the sphere comes at the end of 3.2. Phil and I have also simplified some of his notation so that it is more in line with what I already had. But is the revised version now sufficiently rigorous?

Mike: The extra bit required in Phil's note is the 'twist' condition which Phil will find in Villani's book. This ensures that the inverse of the optimal map is single valued, and is required to show that the optimal map is a map not a 'plan', which could be a joint probability measure. Once you have a map then the mesh cannot tangle. The conditions for this to be true are stated in Villani's theorems but I think absolute continuity of the measure is enough.

Hilary: Phil has put some text into 3.2 about this.

Chris: Second derivative control ..

The second derivative of the potential phi is the Hessian matrix H which is in turn in the Euclidean case the Jacobian matrix J of the transformation. (In the sphere it is related to the Jacobian via the exponential map). This Jacobian is necessarily symmetric and will have eigenvalues lam_1 and lam_2 and orthogonal eigenvectors e_1 and e_2.   The local scaling of the mesh is given by the product lam_1 lam_2 which is directly controlled by the size of the monitor function. The skewness of the mesh can be measured by the quantity Q given by
Q = 1/2 (lam_1/lam_2 + lam_2/lam_1).
This measures how distorted local cells are from being (say) equilateral in the usual Euclidean norm. Now, if the MA equation is posed in the form   det(H) = 1/M  then we have lam_1 lam_2 = 1/M
so if lam_1 < lam_2 (say) we have 
Q = 1/2(1/M 1/lam_2^2 + M lam_2^2)
In other words Q is given by knowing M and also the largest eigen value of J.  Now this is the largest eigenvalue of H and hence is simply the norm of H ie. a measure of the size of the second derivative of phi.

There has been a lot of work in the literature on finding bounds for this. The original results are due to Cafferrelli and Urban for the Euclidean problem and have been extended by 
Loeper and others to different cases such as the sphere).  Basically if M is sufficiently smooth (typically Holder continuous which it will be for our problems)   then the second derivative of phi will also be Holder continuous. This gives a theoretical upper bound on Q which I assume is what MIke is referring to by second derivative control. As Mike says this control is better in periodic than Neumann type boundary conditions, and certainly in the latter we see more skewness close to the boundary.

However in your examples we are also seeing skewness in the interior. This is exactly the situation that Emily Bob and I looked at i our recent JCP paper which I think you have a  copy of. What we did in this paper was to look at two commonly occurring features, namely radially symmetric rings/singularities and also strongly anisotropic linear features
to see what sort of meshes a Monge Ampere solution would be likely to generate. We could study these through looking at exact separable solutions of the MA equation which gave us very precise information in these cases about both Q and also e_1 and e_2 which gives a lot more information than the more general second derivative bounds given above. Thus we were able to exactly assess the anisotropy in these cases. I would like to extend this onto the sphere and am thinking about how to do it.

The key result is that when trying to approximate an anisotropic feature such as a front the MA meshes have a nice tendency to align themselves along this feature.
The work I am now doing is to show precisely how this then translates into error measures on the mesh. This is really quite subtle!

Of course you also get skewness close to the circular features in the paper. This can again be linked to the anisotropy for the ring type solutions which Emily and I considered in 
our paper.

Hilary: I use the test cases from this paper in our paper and I already refer to this paper. I have now put in my paper that my definition of skewness is different from yours. (end of section 4)

Chris: 1. Convexity.

The primary cause of mesh tangling is a local loss of invertibility of the Jacobian matrix J. Now J is the Hessian H of phi, and hence if phi is convex, H is positive definite and thus, in the Euclidean case, we have that J is invertible (it has eigenvalues bounded away from zero).  [Note that proving the solutions of PMA remain convex for all time is quite hard] This convexity in the Euclidean case prevents mesh tangling.  Cost convexity (c-convexity) extends this concept from the Euclidean distance to the Riemannian distance on the sphere, but I think that the same basic idea goes through, so that c-convexity of phi translates over to J being definite and hence prevents mesh tangling.

Hilary: I have put a summary of this at the end of 3.1 for the Euclidean case. Phil has added material on tangling on the sphere to 3.2

Chris:
The usual discretisation of the det(Hessian) operator using finite differences appears to have a chequer-board instability. One of the purposes of the smoothing we used in PMA was to damp this out.

Hilary: I have had similar problems but have solved them by using more compact and more consistent discretisation of the Hessian. When using the finite difference Hessian, all of the steps in 3.4.2.1 are necessary. Omitting the final step leads to an unstable discretisation and a checker-boad in the Hessian

Chris: p2. The comment by Dietachmayer et. al. is not really correct. Agreed r-adaptive methods do control mesh size. However MA based r-adaptive methods have implicit control over resolution in individual directions. This is the main point of my recent paper with Emily. Furthermore, there is now a whole class of r-adaptive methods based on tensor valued monitor functions (see Huang and Russel's book) that have explicit control over directions. 

Hilary: I have modified this to:
"not ALWAYS possible to control the resolution in individual directions"

Chris: p3. Top .. can we quantify what we mean by cheap and expensive in this context. I think this is crucial to selling the paper.

Hilary: I have put in the introduction that Lloyds algorithm is N^2 whereas OT is NlogN. I think that the constant of proportionality could also be very different as Lloyd is an explicit solution of equidistribution whereas solving the MA equation, you use some implicitness. But I really can't say more than this at the moment. Yes, it would be nice, but I just haven't done the work yet.

Chris: p4. Mid.  PMA converges as exp(-lambda tau) in time tau to the desired solution. I'm not sure what you mean by optimal in this context. Note that one of the advantages of PMA is that we can stop the iteration when we think that the mesh is good enough to calculate on. This can give a huge speed up in computational time.

Hilary: I have changed this to "This effectively creates fixed-point iterations but it may be possible to create more convergent iterations, without smoothing towards a uniform mesh."

Chris: p5.  I think a short introduction is needed to say that r-adaptive methods work by identifying a map F from computational to physical space. This map acts on a known mesh tau_C in computational space and maps it into the mesh tau_P in physical space.  tau_C is of course arbitrary. IN the simplest case it is made up of simplices, but in the paper we tend to use hexagons or similar.

Hilary: See new section 3.1

Chris: p6.Top  Maybe replace uniform measure with Lebesgue measure, monoticity with convexity. Also check date of Villani's book. 

Hilary: Other changes made. Villani wrote two books on OT. We only cite the first one (2003). It is easier to understand

Chris: p7.  Mid.  Are each of your iterates phi^n convex?

Hilary: How should I measure the convexity of phi numerically? The phi that I calculates looks pretty smooth. But then the technique for calculating grad(phi) on the vertices can introduce noise which leads to tangled meshes (see section 5.6). I think that we need a better definition of grad(phi) at vertices, that is consistent with the volume calculation of the Hessian. But I do not know precisely what is needed or how to do it.

Chris: p8 Top.  What you say isn't really true about PMA.  What the effect of the smoothing does is it reduces the speed of convergence towards equidistribution, it doesn't push it away from equidistribution. So that if without smoothing the convergence goes like exp(-lambda tau)   then with smoothing it goes like exp(-mu tau) with mu < lambda. I can make this analysis precise if needed. Have you done a local analysis of your fixed point iteration? It may also be worth referring to the Newton methods that Finn et. al. use for this problem. Phil and I tried to summarise these various methods in our recent paper.

Hilary: I have changed this to Budd et al... "smooth the solution towards a uniform mesh. However there may be further scope for improvement by combining the best aspects of the two approaches."

Chris: point 4 ..  This is what Mike was concerned about.  As above the issue is that phi is convex which is more an issue of H(phi) than grad(phi).  Again my comment on the convexity of phi^n applies

Hilary: Future work?

Chris: Rest of section 3 is great : )

Chris: Section 4. I would like to add a bit extra here on skewness and orthogonality and how we have both some control over this and also an understanding of the sort of meshes that MA type approaches will deliver.  A useful local skewness measure is the quantity Q I described in my last email.

Hilary: My definition of skewness is completely different (I now note this clearly at the end of section 4). I am not convinced that using Q as a mesh diagnostic would be valuable. It tells us about a combination of isotropy and orthogonality. But I look at both of these independently. Also, I would only be able to calculate Q for the meshes in Euclidean geometry because I only actually calculate the Hessian for these meshes. On the sphere I use the change in cell volume directly. On the plane, you have already calculated Q for these meshes. No need for me to repeat.

Chris: Section 5.  Mostly great. But 5.5 is central and needs work.  Can you be clear about what is being measured/described in Figure 11. What is the y-axis?

I have put more info in the caption and I have labelled the y-axes

Chris: More generally, I have partial results on the precise link between skewness and monitor function, but the link is quite subtle and we need to work on this as part of the overall project. (Things are clearer with tensor valued monitor functions). We can certainly get a general estimate for the skewness in terms of the second derivatives of phi which are in turn linked to the holder continuity of M. But lots to do here.

Hilary: Looks like future work

Chris: Also you use the word 'unacceptably' in the start of 5.6. This is a rather loaded word and the meshes might be acceptable for some things and not for others. We need to be more precise here.  Also .. do you have speed comparisons between the Lloyd meshes and the optimally transported meshes?

Hilary: I have changed the word "unacceptably" to "very large". Although mesh tangling really is unacceptable!

Chris: As a further comment. In your figure 10 and also figure 12 you state that there is a big difference between Lloyd and OT. However, looking at them there seems to be (i) little difference in Fig 10 so that the (an)-isotropy of the meshes looks similar and (ii) in Fig 12 the OT mesh seems to be less skew.

Hilary: I have put a blue ring round the bad bit in fig 10 and I have described this better in the text. 

Yes, the OT meshes are less skew, using my definition of skewness which is completely different from yours, just uses the same word. 

I have added a paragraph to the end of 5.5 about fig 12 (skewness)

Mike: Just to add that Chris' first comment about loss of invertibility relates to the comment I made to Phil and Hilary yesterday about the 'twist' condition required for the optimal transport plan to be a map. This condition will guarantee no tangling.

Hilary: I use Chris's description in 3.1 because it is more widely accessible. Phil describes the twist condition in 3.2

Chris: A small clarification. When you calculate the really splendid precipitation mesh at the end, do you do a Voronoi calculation after the initial OT calculation, or are you presenting the OT calculation only?
Also .. can you give timings?
I think  these final figures are so good we want to say a bit more about them if possible.

Hilary: No Voronoi calculation. I haven't put a clarification in the paper because I do not use Voronoi tesselations of any of the OT meshes in this paper. 
Timings - very unsure about this. I would rather not. What would they compare with? My implementation is far from optimal. And the meshes in fig 16 are not converged. 
I think that these meshes using precip as a monitor function throw up loads of problems. The closer I look, the worse it gets. They are certainly motiviation for lots more work to improve the methods. I cannot show any diagnostics that will show that these meshes are any good. However I have added some more material in section 5.5 about them ...

